{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>signal</th>\n",
       "      <th>lepton 1 pT</th>\n",
       "      <th>lepton 1 eta</th>\n",
       "      <th>lepton 1 phi</th>\n",
       "      <th>lepton 2 pT</th>\n",
       "      <th>lepton 2 eta</th>\n",
       "      <th>lepton 2 phi</th>\n",
       "      <th>missing energy magnitude</th>\n",
       "      <th>missing energy phi</th>\n",
       "      <th>MET_rel</th>\n",
       "      <th>axial MET</th>\n",
       "      <th>M_R</th>\n",
       "      <th>M_TR_2</th>\n",
       "      <th>R</th>\n",
       "      <th>MT2</th>\n",
       "      <th>S_R</th>\n",
       "      <th>M_Delta_R</th>\n",
       "      <th>dPhi_r_b</th>\n",
       "      <th>cos(theta_r1)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.972861</td>\n",
       "      <td>0.653855</td>\n",
       "      <td>1.176225</td>\n",
       "      <td>1.157156</td>\n",
       "      <td>-1.739873</td>\n",
       "      <td>-0.874309</td>\n",
       "      <td>0.567765</td>\n",
       "      <td>-0.175000</td>\n",
       "      <td>0.810061</td>\n",
       "      <td>-0.252552</td>\n",
       "      <td>1.921887</td>\n",
       "      <td>0.889637</td>\n",
       "      <td>0.410772</td>\n",
       "      <td>1.145621</td>\n",
       "      <td>1.932632</td>\n",
       "      <td>0.994464</td>\n",
       "      <td>1.367815</td>\n",
       "      <td>0.040714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.667973</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>-1.225171</td>\n",
       "      <td>0.506102</td>\n",
       "      <td>-0.338939</td>\n",
       "      <td>1.672543</td>\n",
       "      <td>3.475464</td>\n",
       "      <td>-1.219136</td>\n",
       "      <td>0.012955</td>\n",
       "      <td>3.775174</td>\n",
       "      <td>1.045977</td>\n",
       "      <td>0.568051</td>\n",
       "      <td>0.481928</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.448410</td>\n",
       "      <td>0.205356</td>\n",
       "      <td>1.321893</td>\n",
       "      <td>0.377584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.444840</td>\n",
       "      <td>-0.134298</td>\n",
       "      <td>-0.709972</td>\n",
       "      <td>0.451719</td>\n",
       "      <td>-1.613871</td>\n",
       "      <td>-0.768661</td>\n",
       "      <td>1.219918</td>\n",
       "      <td>0.504026</td>\n",
       "      <td>1.831248</td>\n",
       "      <td>-0.431385</td>\n",
       "      <td>0.526283</td>\n",
       "      <td>0.941514</td>\n",
       "      <td>1.587535</td>\n",
       "      <td>2.024308</td>\n",
       "      <td>0.603498</td>\n",
       "      <td>1.562374</td>\n",
       "      <td>1.135454</td>\n",
       "      <td>0.180910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.381256</td>\n",
       "      <td>-0.976145</td>\n",
       "      <td>0.693152</td>\n",
       "      <td>0.448959</td>\n",
       "      <td>0.891753</td>\n",
       "      <td>-0.677328</td>\n",
       "      <td>2.033060</td>\n",
       "      <td>1.533041</td>\n",
       "      <td>3.046260</td>\n",
       "      <td>-1.005285</td>\n",
       "      <td>0.569386</td>\n",
       "      <td>1.015211</td>\n",
       "      <td>1.582217</td>\n",
       "      <td>1.551914</td>\n",
       "      <td>0.761215</td>\n",
       "      <td>1.715464</td>\n",
       "      <td>1.492257</td>\n",
       "      <td>0.090719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.309996</td>\n",
       "      <td>-0.690089</td>\n",
       "      <td>-0.676259</td>\n",
       "      <td>1.589283</td>\n",
       "      <td>-0.693326</td>\n",
       "      <td>0.622907</td>\n",
       "      <td>1.087562</td>\n",
       "      <td>-0.381742</td>\n",
       "      <td>0.589204</td>\n",
       "      <td>1.365479</td>\n",
       "      <td>1.179295</td>\n",
       "      <td>0.968218</td>\n",
       "      <td>0.728563</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.083158</td>\n",
       "      <td>0.043429</td>\n",
       "      <td>1.154854</td>\n",
       "      <td>0.094859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.456398</td>\n",
       "      <td>1.099371</td>\n",
       "      <td>1.512453</td>\n",
       "      <td>0.751772</td>\n",
       "      <td>0.638967</td>\n",
       "      <td>-0.742216</td>\n",
       "      <td>0.322601</td>\n",
       "      <td>1.321054</td>\n",
       "      <td>0.169502</td>\n",
       "      <td>0.359941</td>\n",
       "      <td>0.489256</td>\n",
       "      <td>0.416168</td>\n",
       "      <td>0.754829</td>\n",
       "      <td>0.303750</td>\n",
       "      <td>0.461067</td>\n",
       "      <td>0.345541</td>\n",
       "      <td>0.733242</td>\n",
       "      <td>0.186044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.437818</td>\n",
       "      <td>-1.119883</td>\n",
       "      <td>-1.336823</td>\n",
       "      <td>0.502320</td>\n",
       "      <td>-1.717515</td>\n",
       "      <td>1.017067</td>\n",
       "      <td>0.215619</td>\n",
       "      <td>-0.461200</td>\n",
       "      <td>0.323671</td>\n",
       "      <td>0.173626</td>\n",
       "      <td>0.411898</td>\n",
       "      <td>0.370525</td>\n",
       "      <td>0.798260</td>\n",
       "      <td>0.671369</td>\n",
       "      <td>0.385910</td>\n",
       "      <td>0.515522</td>\n",
       "      <td>0.479110</td>\n",
       "      <td>0.029058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571656</td>\n",
       "      <td>0.205696</td>\n",
       "      <td>0.425950</td>\n",
       "      <td>0.578514</td>\n",
       "      <td>0.927399</td>\n",
       "      <td>-1.101478</td>\n",
       "      <td>0.116555</td>\n",
       "      <td>1.549753</td>\n",
       "      <td>0.174421</td>\n",
       "      <td>0.223450</td>\n",
       "      <td>0.523164</td>\n",
       "      <td>0.289889</td>\n",
       "      <td>0.491710</td>\n",
       "      <td>0.334593</td>\n",
       "      <td>0.514246</td>\n",
       "      <td>0.268207</td>\n",
       "      <td>0.315795</td>\n",
       "      <td>0.125728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.112812</td>\n",
       "      <td>0.742983</td>\n",
       "      <td>-0.330539</td>\n",
       "      <td>0.805253</td>\n",
       "      <td>-0.028887</td>\n",
       "      <td>-1.446679</td>\n",
       "      <td>2.299946</td>\n",
       "      <td>1.450429</td>\n",
       "      <td>2.989110</td>\n",
       "      <td>-1.894770</td>\n",
       "      <td>1.445125</td>\n",
       "      <td>2.548166</td>\n",
       "      <td>1.564721</td>\n",
       "      <td>2.393632</td>\n",
       "      <td>1.554566</td>\n",
       "      <td>2.148468</td>\n",
       "      <td>1.179117</td>\n",
       "      <td>0.688057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.001869</td>\n",
       "      <td>-0.471788</td>\n",
       "      <td>0.555614</td>\n",
       "      <td>1.233368</td>\n",
       "      <td>1.255548</td>\n",
       "      <td>-1.052491</td>\n",
       "      <td>0.437615</td>\n",
       "      <td>-1.333052</td>\n",
       "      <td>0.326858</td>\n",
       "      <td>-0.111678</td>\n",
       "      <td>1.435708</td>\n",
       "      <td>0.755201</td>\n",
       "      <td>0.466779</td>\n",
       "      <td>0.454541</td>\n",
       "      <td>1.446331</td>\n",
       "      <td>0.592259</td>\n",
       "      <td>1.325197</td>\n",
       "      <td>0.083014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   signal  lepton 1 pT  lepton 1 eta  lepton 1 phi  lepton 2 pT  lepton 2 eta  \\\n",
       "0     0.0     0.972861      0.653855      1.176225     1.157156     -1.739873   \n",
       "1     1.0     1.667973      0.064191     -1.225171     0.506102     -0.338939   \n",
       "2     1.0     0.444840     -0.134298     -0.709972     0.451719     -1.613871   \n",
       "3     1.0     0.381256     -0.976145      0.693152     0.448959      0.891753   \n",
       "4     1.0     1.309996     -0.690089     -0.676259     1.589283     -0.693326   \n",
       "5     0.0     0.456398      1.099371      1.512453     0.751772      0.638967   \n",
       "6     0.0     0.437818     -1.119883     -1.336823     0.502320     -1.717515   \n",
       "7     0.0     0.571656      0.205696      0.425950     0.578514      0.927399   \n",
       "8     1.0     2.112812      0.742983     -0.330539     0.805253     -0.028887   \n",
       "9     0.0     1.001869     -0.471788      0.555614     1.233368      1.255548   \n",
       "\n",
       "   lepton 2 phi  missing energy magnitude  missing energy phi   MET_rel  \\\n",
       "0     -0.874309                  0.567765           -0.175000  0.810061   \n",
       "1      1.672543                  3.475464           -1.219136  0.012955   \n",
       "2     -0.768661                  1.219918            0.504026  1.831248   \n",
       "3     -0.677328                  2.033060            1.533041  3.046260   \n",
       "4      0.622907                  1.087562           -0.381742  0.589204   \n",
       "5     -0.742216                  0.322601            1.321054  0.169502   \n",
       "6      1.017067                  0.215619           -0.461200  0.323671   \n",
       "7     -1.101478                  0.116555            1.549753  0.174421   \n",
       "8     -1.446679                  2.299946            1.450429  2.989110   \n",
       "9     -1.052491                  0.437615           -1.333052  0.326858   \n",
       "\n",
       "   axial MET       M_R    M_TR_2         R       MT2       S_R  M_Delta_R  \\\n",
       "0  -0.252552  1.921887  0.889637  0.410772  1.145621  1.932632   0.994464   \n",
       "1   3.775174  1.045977  0.568051  0.481928  0.000000  0.448410   0.205356   \n",
       "2  -0.431385  0.526283  0.941514  1.587535  2.024308  0.603498   1.562374   \n",
       "3  -1.005285  0.569386  1.015211  1.582217  1.551914  0.761215   1.715464   \n",
       "4   1.365479  1.179295  0.968218  0.728563  0.000000  1.083158   0.043429   \n",
       "5   0.359941  0.489256  0.416168  0.754829  0.303750  0.461067   0.345541   \n",
       "6   0.173626  0.411898  0.370525  0.798260  0.671369  0.385910   0.515522   \n",
       "7   0.223450  0.523164  0.289889  0.491710  0.334593  0.514246   0.268207   \n",
       "8  -1.894770  1.445125  2.548166  1.564721  2.393632  1.554566   2.148468   \n",
       "9  -0.111678  1.435708  0.755201  0.466779  0.454541  1.446331   0.592259   \n",
       "\n",
       "   dPhi_r_b  cos(theta_r1)  \n",
       "0  1.367815       0.040714  \n",
       "1  1.321893       0.377584  \n",
       "2  1.135454       0.180910  \n",
       "3  1.492257       0.090719  \n",
       "4  1.154854       0.094859  \n",
       "5  0.733242       0.186044  \n",
       "6  0.479110       0.029058  \n",
       "7  0.315795       0.125728  \n",
       "8  1.179117       0.688057  \n",
       "9  1.325197       0.083014  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns=[\"signal\", \"lepton 1 pT\", \"lepton 1 eta\", \"lepton 1 phi\", \"lepton 2 pT\", \"lepton 2 eta\", \n",
    "         \"lepton 2 phi\", \"missing energy magnitude\", \"missing energy phi\", \"MET_rel\", \n",
    "         \"axial MET\", \"M_R\", \"M_TR_2\", \"R\", \"MT2\", \"S_R\", \"M_Delta_R\", \"dPhi_r_b\", \"cos(theta_r1)\"]\n",
    "\n",
    "train_dataset = pd.read_csv('/Users/jai/SUSY.csv', names=columns, nrows=1500000)\n",
    "test_dataset = pd.read_csv('/Users/jai/SUSY.csv', names=columns, nrows=50000)\n",
    "\n",
    "\n",
    "train_dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = np.array(train_dataset.iloc[:,1:])\n",
    "train_labels = np.array(train_dataset[\"signal\"])\n",
    "\n",
    "test_features = np.array(test_dataset.iloc[:,1:])\n",
    "test_labels = test_dataset[\"signal\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500000, 18)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import models, layers, optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "model.add(layers.Dense(16, input_shape=(18, ), activation='relu'))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(128, activation='relu'))\n",
    "model.add(layers.Dense(256, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1470000 samples, validate on 30000 samples\n",
      "Epoch 1/20\n",
      "1470000/1470000 [==============================] - 112s 76us/step - loss: 0.4440 - accuracy: 0.7946 - val_loss: 0.4355 - val_accuracy: 0.8015\n",
      "Epoch 2/20\n",
      "1470000/1470000 [==============================] - 108s 74us/step - loss: 0.4397 - accuracy: 0.7981 - val_loss: 0.4388 - val_accuracy: 0.8001\n",
      "Epoch 3/20\n",
      "1349700/1470000 [==========================>...] - ETA: 9s - loss: 0.4394 - accuracy: 0.7987"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5a9f1b09fb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m   1237\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1238\u001b[0m                                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1239\u001b[0;31m                                         validation_freq=validation_freq)\n\u001b[0m\u001b[1;32m   1240\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1241\u001b[0m     def evaluate(self,\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, fit_function, fit_inputs, out_labels, batch_size, epochs, verbose, callbacks, val_function, val_inputs, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq)\u001b[0m\n\u001b[1;32m    194\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3738\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3739\u001b[0m       \u001b[0mconverted_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3740\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mconverted_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3742\u001b[0m     \u001b[0;31m# EagerTensor.numpy() will often make a copy to ensure memory safety.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1079\u001b[0m       \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m \u001b[0mpositional\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mkeyword\u001b[0m \u001b[0margument\u001b[0m \u001b[0mcombinations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m     \"\"\"\n\u001b[0;32m-> 1081\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1119\u001b[0m       raise TypeError(\"Keyword arguments {} unknown. Expected {}.\".format(\n\u001b[1;32m   1120\u001b[0m           list(kwargs.keys()), list(self._arg_keywords)))\n\u001b[0;32m-> 1121\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_features, train_labels,epochs=20, batch_size=100, validation_split=0.02)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
